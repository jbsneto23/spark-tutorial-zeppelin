{"paragraphs":[{"title":"Comparação no desenvolvimento de consultas (queries) entre Apache Pig X Spark SQL","text":"%md\n# Comparação no desenvolvimento de consultas (queries) entre o Apache PIG x Spark SQL\n\n### Contextualizando\n\nEste trabalho é a continuação do projeto \"Exhibiting violence through communities analysis in social networks\" que foi desenvolvido no decorrer do curso _Data Centrics Sciences_, ministrado por Genoveva Vargas-Solar e participação de Javier Espinosa.\n\n### Discentes\n\nDenis Albuquerque, João Batista e Roberta Freitas.\n\n### Objetivo\n\nComparar empiricamente e descrever o desenvolvimento de consultas com as ferramentas: Apache Pig e Spark SQL.","user":"anonymous","dateUpdated":"2017-12-12T17:59:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Comparação no desenvolvimento de consultas (queries) entre o Apache PIG x Spark SQL</h1>\n<h3>Contextualizando</h3>\n<p>Este trabalho é a continuação do projeto &ldquo;Exhibiting violence through communities analysis in social networks&rdquo; que foi desenvolvido no decorrer do curso <em>Data Centrics Sciences</em>, ministrado por Genoveva Vargas-Solar e participação de Javier Espinosa.</p>\n<h3>Discentes</h3>\n<p>Denis Albuquerque, João Batista e Roberta Freitas.</p>\n<h3>Objetivo</h3>\n<p>Comparar empiricamente e descrever o desenvolvimento de consultas com as ferramentas: Apache Pig e Spark SQL.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315921_-712328118","id":"20171205-033139_1582218185","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T17:59:07+0000","dateFinished":"2017-12-12T17:59:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5452"},{"title":"","text":"%md\n\n# Primeiro Dataset utilizado: Usuários\n\nEsse dataset de usuários possui diversas informações relativas ao twitter de um usuário, como: id, name, etc. \n\nO primeiro desafio é fazer com que esses dados sejam analisados corretamente a partir do seu carregamento.\nOu seja, a transformação das dados que estão no formato  \".csv\" em dados que possam ser lidos pelas ferramentas.\n\n### Utilizando PIG\n\nNo caso de PIG, como pode ser visto abaixo, criamos a classe Users e usamos o \"**LOAD**\" para carregar o **users.csv**. O PigStorage é usado para o PIG entender que a vírgula separa cada um dos parâmetros. Em seguida, cada parâmetro deve ter seu nome e tipo identificado, para que a leitura seja feita corretamente.\n","user":"anonymous","dateUpdated":"2017-12-12T20:08:42+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Primeiro Dataset utilizado: Usuários</h1>\n<p>Esse dataset de usuários possui diversas informações relativas ao twitter de um usuário, como: id, name, etc. </p>\n<p>O primeiro desafio é fazer com que esses dados sejam analisados corretamente a partir do seu carregamento.<br/>Ou seja, a transformação das dados que estão no formato &ldquo;.csv&rdquo; em dados que possam ser lidos pelas ferramentas.</p>\n<h3>Utilizando PIG</h3>\n<p>No caso de PIG, como pode ser visto abaixo, criamos a classe Users e usamos o &ldquo;<strong>LOAD</strong>&rdquo; para carregar o <strong>users.csv</strong>. O PigStorage é usado para o PIG entender que a vírgula separa cada um dos parâmetros. Em seguida, cada parâmetro deve ter seu nome e tipo identificado, para que a leitura seja feita corretamente.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315925_-713867114","id":"20171205-035316_1381030156","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T20:08:42+0000","dateFinished":"2017-12-12T20:08:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5453"},{"title":"PIG: carregando dataset de usuários","text":"%pig\n\nUsers = LOAD '/data/users.csv' using PigStorage(',') as (\n      id: chararray, \n      name: chararray, \n      screen_name: chararray, \n      location: chararray, \n      url: chararray, \n      description: chararray, \n      verified: boolean,\n      followers_count: int,\n      friends_count: int,\n      listed_count: int, \n      favourites_count: int, \n      statuses_count: int, \n      created_at: chararray, \n      utc_offset: int,\n      time_zone: chararray, \n      geo_enabled: boolean,\n      lang: chararray, \n      profile_image_url_https: chararray\n);","dateUpdated":"2017-12-12T17:55:15+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315926_-712712867","id":"20171130-212956_2028967260","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5454"},{"text":"%md\n\n# Utilizando SPARK\n\nNo caso do Spark, existe uma semelhança na leitura dos dados com o PIG, uma vez que ambos terão que definir o nome e os tipos dos parâmetros. \n\n**1. Primeiro passo**: definir uma classe ( **User**) cujos atributos determinam o nome e o tipo de todos os parâmetros.\n\n**2. Segundo passo**: definir uma função ( **mapper**) que transforme uma linha de texto do dataset em um objeto da classe definida. Utilizamos funções auxiliares para conversão das strings de valores do tipo inteiro ( **convertToInt**) e booleano ( **convertToBool**). \n\n**3. Terceiro Passo**: realizar a leitura das linhas de texto do arquivo do dataset, mapeando cada linha para a função definida (mapper), resultando em um Array de **User**.\n\n","user":"anonymous","dateUpdated":"2017-12-13T01:16:05+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Utilizando SPARK</h1>\n<p>No caso do Spark, existe uma semelhança na leitura dos dados com o PIG, uma vez que ambos terão que definir o nome e os tipos dos parâmetros. </p>\n<p><strong>1. Primeiro passo</strong>: definir uma classe ( <strong>User</strong>) cujos atributos determinam o nome e o tipo de todos os parâmetros.</p>\n<p><strong>2. Segundo passo</strong>: definir uma função ( <strong>mapper</strong>) que transforme uma linha de texto do dataset em um objeto da classe definida. Utilizamos funções auxiliares para conversão das strings de valores do tipo inteiro ( <strong>convertToInt</strong>) e booleano ( <strong>convertToBool</strong>). </p>\n<p><strong>3. Terceiro Passo</strong>: realizar a leitura das linhas de texto do arquivo do dataset, mapeando cada linha para a função definida (mapper), resultando em um Array de <strong>User</strong>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315928_-715021360","id":"20171205-035324_1482679102","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T20:10:33+0000","dateFinished":"2017-12-12T20:10:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5455"},{"title":"SPARK: carregando dataset de usuários","text":"%spark \n\nfinal case class User(     \n      id: String, \n      name: String, \n      screen_name: String, \n      location: String, \n      url: String, \n      description: String, \n      verified: Option[Boolean],\n      followers_count: Option[Int],\n      friends_count: Option[Int],\n      listed_count: Option[Int], \n      favourites_count: Option[Int], \n      statuses_count: Option[Int], \n      created_at: String, \n      utc_offset: Option[Int],\n      time_zone: String, \n      geo_enabled: Option[Boolean],\n      lang: String, \n      profile_image_url_https: String\n)\n\ndef convertToInt(str : String) : Option [Int] = {\n    try {\n        return Some(str.toInt)\n    } catch {\n        case e:Exception => return None\n    }\n}\n\ndef convertToBool(str : String) : Option [Boolean] = {\n    try {\n        return Some(str.toBoolean)\n    } catch {\n        case e:Exception => return None\n    }\n}\n\ndef mapper(line: String) : User = {\n    val fields = line.split(\",\")\n    User(\n        fields(0),\n        fields(1),\n        fields(2),\n        fields(3),\n        fields(4),\n        fields(5),\n        convertToBool(fields(6)),\n        convertToInt(fields(7)),\n        convertToInt(fields(8)),\n        convertToInt(fields(9)),\n        convertToInt(fields(10)),        \n        convertToInt(fields(11)),\n        fields(12),\n        convertToInt(fields(13)),\n        fields(14),\n        convertToBool(fields(15)),\n        fields(16),\n        fields(17)\n    )\n}\n\nval users = sc.textFile(\"/data/users.csv\").map(mapper)","dateUpdated":"2017-12-12T17:55:15+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315928_-715021360","id":"20171130-190338_1546486108","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5456"},{"text":"%md\n# Pig x Spark: Comparação de Carregamento do Dataset de Users\n\nNo tangente a programação feita para carregar corretamente esse dataset, o PIG apresenta um processo simplificado que abstrai alguns tratamentos de dados. \nEnquanto na utilização de Spark foram feitos através do uso de funções auxiliares para a leitura correta dos tipos boolean e inteiro.\n","user":"anonymous","dateUpdated":"2017-12-12T20:14:07+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Pig x Spark: Comparação de Carregamento do Dataset de Users</h1>\n<p>No tangente a programação feita para carregar corretamente esse dataset, o PIG apresenta um processo simplificado que abstrai alguns tratamentos de dados.<br/>Enquanto na utilização de Spark foram feitos através do uso de funções auxiliares para a leitura correta dos tipos boolean e inteiro.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315929_-715406109","id":"20171205-044616_26809096","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T20:14:07+0000","dateFinished":"2017-12-12T20:14:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5457"},{"text":"%md\n\n# Consultas com PIG\n\nListar os 10 primeiros usuários, da tabela Users e mostrar o **id, name e screen_name**.\n\nEm PIG, para exibir o resultado na tela tem que ser feito a instrução _DUMP_ seguida da expressão da query ou de um _alias_ para expressão. Caso a consulta devesse ser armazenada, a instrução utilizada seria \"Store\", que grava a saída no sistema de arquivos.\n","user":"anonymous","dateUpdated":"2017-12-12T20:17:19+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Consultas com PIG</h1>\n<p>Listar os 10 primeiros usuários, da tabela Users e mostrar o <strong>id, name e screen_name</strong>.</p>\n<p>Em PIG, para exibir o resultado na tela tem que ser feito a instrução <em>DUMP</em> seguida da expressão da query ou de um <em>alias</em> para expressão. Caso a consulta devesse ser armazenada, a instrução utilizada seria &ldquo;Store&rdquo;, que grava a saída no sistema de arquivos.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315929_-715406109","id":"20171205-045836_398447885","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T20:17:19+0000","dateFinished":"2017-12-12T20:17:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5458"},{"title":"PIG Latin: listando 10 primeiros usuários","text":"%pig\n\nResult = LIMIT Users 10;\nResult = FOREACH Result GENERATE id, name, screen_name; \n\nDUMP Result;","dateUpdated":"2017-12-13T01:11:04+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315929_-715406109","id":"20171205-014157_995324452","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5459"},{"text":"%md\n# Outra forma de fazer uma consulta com PIG\nExiste um modo mais simplificado de realizar consultas com PIG dentro do Zeppelin, que seria chamar o interpretador \"**%pig**\" e dizer que será colocado uma consulta \"**.query**\".","user":"anonymous","dateUpdated":"2017-12-13T00:56:33+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Outra forma de fazer uma consulta com PIG</h1>\n<p>Existe um modo mais simplificado de realizar consultas com PIG dentro do Zeppelin, que seria chamar o interpretador &ldquo;<strong>%pig</strong>&rdquo; e dizer que será colocado uma consulta &ldquo;<strong>.query</strong>&rdquo;.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513126113447_165645104","id":"20171213-004833_133235143","dateCreated":"2017-12-13T00:48:33+0000","dateStarted":"2017-12-13T00:56:33+0000","dateFinished":"2017-12-13T00:56:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5460"},{"text":"%pig.query\n\nFOREACH (LIMIT Users 10) GENERATE id, name, screen_name;\n","user":"anonymous","dateUpdated":"2017-12-13T00:48:10+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing. Pig script failed to parse: <line 1, column 54> Undefined alias: Users\n\tat org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1833)\n\tat org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1767)\n\tat org.apache.pig.PigServer.registerQuery(PigServer.java:708)\n\tat org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:1110)\n\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:512)\n\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n\tat org.apache.pig.PigServer.registerScript(PigServer.java:781)\n\tat org.apache.pig.PigServer.registerScript(PigServer.java:858)\n\tat org.apache.pig.PigServer.registerScript(PigServer.java:821)\n\tat org.apache.zeppelin.pig.PigQueryInterpreter.interpret(PigQueryInterpreter.java:92)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:498)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: Failed to parse: Pig script failed to parse: <line 1, column 54> Undefined alias: Users\n\tat org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:199)\n\tat org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1820)\n\t... 20 more\nCaused by: <line 1, column 54> Undefined alias: Users\n\tat org.apache.pig.parser.AstValidator.validateAliasRef(AstValidator.java:278)\n\tat org.apache.pig.parser.AstValidator.rel(AstValidator.java:6557)\n\tat org.apache.pig.parser.AstValidator.limit_clause(AstValidator.java:11084)\n\tat org.apache.pig.parser.AstValidator.op_clause(AstValidator.java:1723)\n\tat org.apache.pig.parser.AstValidator.rel(AstValidator.java:6593)\n\tat org.apache.pig.parser.AstValidator.foreach_clause(AstValidator.java:13946)\n\tat org.apache.pig.parser.AstValidator.op_clause(AstValidator.java:1923)\n\tat org.apache.pig.parser.AstValidator.general_statement(AstValidator.java:1035)\n\tat org.apache.pig.parser.AstValidator.statement(AstValidator.java:499)\n\tat org.apache.pig.parser.AstValidator.query(AstValidator.java:373)\n\tat org.apache.pig.parser.QueryParserDriver.validateAst(QueryParserDriver.java:258)\n\tat org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:186)\n\t... 21 more\n"}]},"apps":[],"jobName":"paragraph_1513101315930_-714251863","id":"20171205-022504_1819103946","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-13T00:48:11+0000","dateFinished":"2017-12-13T00:48:15+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5461"},{"text":"%md\n# Segunda Consulta  com PIG Latin: Contar número de usuários\n\nNessa forma de consulta, o resultado é exibido na tela com o uso do DUMP e antes é agrupado todos os usuários e depois feito um foreach para contar o número de usuários\n\n","user":"anonymous","dateUpdated":"2017-12-13T01:09:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Segunda Consulta com PIG Latin: Contar número de usuários</h1>\n<p>Nessa forma de consulta, o resultado é exibido na tela com o uso do DUMP e antes é agrupado todos os usuários e depois feito um foreach para contar o número de usuários</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513127064493_-2123257871","id":"20171213-010424_1389329364","dateCreated":"2017-12-13T01:04:24+0000","dateStarted":"2017-12-13T01:09:32+0000","dateFinished":"2017-12-13T01:09:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5462"},{"title":"PIG Latin: contando número de usuários (linhas)","text":"%pig\n\nGroups = GROUP Users ALL;\nResult = FOREACH Groups GENERATE COUNT_STAR($1);\n\nDUMP Result;","user":"anonymous","dateUpdated":"2017-12-13T01:07:23+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1000: Error during parsing. Pig script failed to parse: <line 1, column 15> Undefined alias: Users\n\tat org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1833)\n\tat org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1767)\n\tat org.apache.pig.PigServer.registerQuery(PigServer.java:708)\n\tat org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:1110)\n\tat org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:512)\n\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)\n\tat org.apache.pig.PigServer.registerScript(PigServer.java:781)\n\tat org.apache.pig.PigServer.registerScript(PigServer.java:858)\n\tat org.apache.pig.PigServer.registerScript(PigServer.java:821)\n\tat org.apache.zeppelin.pig.PigInterpreter.interpret(PigInterpreter.java:100)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:498)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: Failed to parse: Pig script failed to parse: <line 1, column 15> Undefined alias: Users\n\tat org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:199)\n\tat org.apache.pig.PigServer$Graph.parseQuery(PigServer.java:1820)\n\t... 20 more\nCaused by: <line 1, column 15> Undefined alias: Users\n\tat org.apache.pig.parser.AstValidator.validateAliasRef(AstValidator.java:278)\n\tat org.apache.pig.parser.AstValidator.rel(AstValidator.java:6557)\n\tat org.apache.pig.parser.AstValidator.group_item(AstValidator.java:6302)\n\tat org.apache.pig.parser.AstValidator.group_clause(AstValidator.java:6089)\n\tat org.apache.pig.parser.AstValidator.op_clause(AstValidator.java:1643)\n\tat org.apache.pig.parser.AstValidator.general_statement(AstValidator.java:1035)\n\tat org.apache.pig.parser.AstValidator.statement(AstValidator.java:499)\n\tat org.apache.pig.parser.AstValidator.query(AstValidator.java:373)\n\tat org.apache.pig.parser.QueryParserDriver.validateAst(QueryParserDriver.java:258)\n\tat org.apache.pig.parser.QueryParserDriver.parse(QueryParserDriver.java:186)\n\t... 21 more\n"}]},"apps":[],"jobName":"paragraph_1513101315930_-714251863","id":"20171130-200342_793160850","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-13T01:07:23+0000","dateFinished":"2017-12-13T01:07:23+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5463"},{"text":"%md\n# Consulta em SPARK: Listar os 10  primeiros usuários\n\nPara efeito de demonstração de como seria uma consulta simples em spark","user":"anonymous","dateUpdated":"2017-12-13T01:23:00+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127080177_247595499","id":"20171213-010440_1465720271","dateCreated":"2017-12-13T01:04:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5464","dateFinished":"2017-12-13T01:11:26+0000","dateStarted":"2017-12-13T01:11:26+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Consulta em SPARK para listar os 10 primeiros usuários</h1>\n</div>"}]}},{"title":"Spark: listando os 10 primeiros usuários","text":"%spark\n\nusers.take(10).foreach(usr => println(usr.id + \",\" + usr.name + \",\" + usr.screen_name));","dateUpdated":"2017-12-13T01:23:12+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315930_-714251863","id":"20171205-014528_2087065679","dateCreated":"2017-12-12T17:55:15+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5465","user":"anonymous","dateFinished":"2017-12-13T01:23:09+0000","dateStarted":"2017-12-13T01:23:09+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:26: error: not found: value users\n       users.take(10).foreach(usr => println(usr.id + \",\" + usr.name + \",\" + usr.screen_name));\n       ^\n"}]}},{"text":"%md\n# Segunda Consulta em SPARK para contar o número de usuários\n\nEm Spark, basta apenas chamar a tabela  **users**.count .\n","user":"anonymous","dateUpdated":"2017-12-13T01:23:44+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127083532_421886751","id":"20171213-010443_2027821070","dateCreated":"2017-12-13T01:04:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5466","dateFinished":"2017-12-13T01:23:44+0000","dateStarted":"2017-12-13T01:23:44+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Segunda Consulta em SPARK para contar o número de usuários</h1>\n<p>Em Spark, basta apenas chamar a tabela <strong>users</strong>.count .</p>\n</div>"}]}},{"title":"Spark: contando número de usuários (linhas) ","text":"%spark\n\nusers.count","dateUpdated":"2017-12-13T01:10:16+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315930_-714251863","id":"20171130-212438_838601865","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5467"},{"text":"%md\n\n# Spark SQL: Como converter RDD para DataFrame\n\nAlgumas informações importantes sobre como criar um DataFrame em Spark.\n\n**1. O que é DataFrame?**\n\nUm DataFrame é um conjunto de dados organizado em named columns. Ele equivale conceitualmente a uma tabela em um banco de dados relacional, mas com otimizações mais ricas. Os DataFrames podem ser construídos a partir de uma ampla variedade de fontes, tais como: arquivos de dados estruturados, bancos de dados externos ou RDDs existentes. A API DataFrame está disponível em Scala, Java, Python e R. Em Scala e Java, um DataFrame é representado por um conjunto de dados de linhas. Na API Scala, o DataFrame é simplesmente um tipo de alias do Dataset [Row]. Enquanto, na API Java, os usuários precisam usar o Dataset <Row> para representar um DataFrame.\n\n**2. O que é o registerTempTable(tableName)?**  \n\nÉ um método de um DataFrame que além de poder usar os métodos fornecidos pelo Spark de um DataFrame, você também pode emitir consultas SQL através do método sqlContext.sql (sqlQuery), que utilize esse DataFrame como uma tabela SQL. O parâmetro tableName especifica o nome da tabela a ser usado para esse DataFrame nas consultas SQL.\n","dateUpdated":"2017-12-13T01:59:40+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315930_-714251863","id":"20171205-161438_1190981993","dateCreated":"2017-12-12T17:55:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5468","user":"anonymous","dateFinished":"2017-12-13T01:59:40+0000","dateStarted":"2017-12-13T01:59:40+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Spark SQL: Como converter RDD para DataFrame</h1>\n<p>Algumas informações importantes sobre como criar um DataFrame em Spark.</p>\n<p><strong>1. O que é DataFrame?</strong></p>\n<p>Um DataFrame é um conjunto de dados organizado em named columns. Ele equivale conceitualmente a uma tabela em um banco de dados relacional, mas com otimizações mais ricas. Os DataFrames podem ser construídos a partir de uma ampla variedade de fontes, tais como: arquivos de dados estruturados, bancos de dados externos ou RDDs existentes. A API DataFrame está disponível em Scala, Java, Python e R. Em Scala e Java, um DataFrame é representado por um conjunto de dados de linhas. Na API Scala, o DataFrame é simplesmente um tipo de alias do Dataset [Row]. Enquanto, na API Java, os usuários precisam usar o Dataset <Row> para representar um DataFrame.</p>\n<p><strong>2. O que é o registerTempTable(tableName)?</strong> </p>\n<p>É um método de um DataFrame que além de poder usar os métodos fornecidos pelo Spark de um DataFrame, você também pode emitir consultas SQL através do método sqlContext.sql (sqlQuery), que utilize esse DataFrame como uma tabela SQL. O parâmetro tableName especifica o nome da tabela a ser usado para esse DataFrame nas consultas SQL.</p>\n</div>"}]}},{"title":"SPARK SQL: convertendo RDD para DataFrame","text":"%spark \n\nimport sqlContext.implicits._\n\nval usersDF = users.toDF\n\nusersDF.registerTempTable(\"users\")\nusersDF.printSchema","dateUpdated":"2017-12-12T17:55:15+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315931_-714636611","id":"20171130-212354_436780378","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5469"},{"text":"%md\n# Utilizando o DataFrame para consulta Spark SQL\n\nEsse é o exemplo de uma consulta feita utilizando o DataFrame.\n","user":"anonymous","dateUpdated":"2017-12-13T01:19:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127621702_1130776471","id":"20171213-011341_291865825","dateCreated":"2017-12-13T01:13:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8064","dateFinished":"2017-12-13T01:19:51+0000","dateStarted":"2017-12-13T01:19:51+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Utilizando o DataFrame para consulta Spark SQL</h1>\n<p>Esse é o exemplo de uma consulta feita utilizando o DataFrame.</p>\n</div>"}]}},{"title":"SPARK SQL: listando 10 usuarios ","text":"%spark \n\nprintln(\"DataFrame API\")\n\nusersDF.select(\"id\",\"name\",\"screen_name\").limit(10).show\n\nprintln(\"SQL\")\n\nsql(\"select id, name, screen_name from users limit 10\").show","dateUpdated":"2017-12-13T01:19:03+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315931_-714636611","id":"20171205-020251_2136860616","dateCreated":"2017-12-12T17:55:15+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5470","user":"anonymous","dateFinished":"2017-12-13T01:17:48+0000","dateStarted":"2017-12-13T01:17:47+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Dataframe API\n<console>:27: error: not found: value usersDF\n       usersDF.select(\"id\",\"name\",\"screen_name\").limit(10).show\n       ^\n"}]}},{"text":"%md\n# Consulta em SQL\n\nEssa é uma consulta simples para listar os 10 primeiros usuários, selecionando o **id, name e o screen_name** da tabela **Users(usuários)**.\n","user":"anonymous","dateUpdated":"2017-12-13T01:21:40+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127629062_-1503983997","id":"20171213-011349_284315124","dateCreated":"2017-12-13T01:13:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8127","dateFinished":"2017-12-13T01:21:40+0000","dateStarted":"2017-12-13T01:21:40+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Consulta em SQL</h1>\n<p>Essa é uma consulta simples para listar os 10 primeiros usuários, selecionando o <strong>id, name e o screen_name</strong> da tabela <strong>Users(usuários)</strong>.</p>\n</div>"}]}},{"title":"SQL: listando 10 primeiros usuários","text":"%sql \n\nselect id, name, screen_name from users limit 10","dateUpdated":"2017-12-13T01:20:18+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315931_-714636611","id":"20171205-020643_268693600","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5471"},{"text":"%md\n# Consulta simples em SQL para contar o número de usuários\n\n","user":"anonymous","dateUpdated":"2017-12-13T01:24:18+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127652522_680281481","id":"20171213-011412_1538369597","dateCreated":"2017-12-13T01:14:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8211","dateFinished":"2017-12-13T01:24:18+0000","dateStarted":"2017-12-13T01:24:18+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Consulta simples em SQL para contar o número de usuários</h1>\n</div>"}]}},{"title":"SQL : contando número de usuários (linhas)","text":"%sql\n\nselect count(*) from users","dateUpdated":"2017-12-12T17:55:15+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315931_-714636611","id":"20171205-013154_1882572098","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5472"},{"text":"%md\n# Como carregar o Dataset de Tweets em PIG\n\nO processo é semelhante ao feito no Dataset da tabela Users.","user":"anonymous","dateUpdated":"2017-12-13T01:25:16+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127663530_-1782111480","id":"20171213-011423_1515162533","dateCreated":"2017-12-13T01:14:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8283","dateFinished":"2017-12-13T01:25:16+0000","dateStarted":"2017-12-13T01:25:16+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Como carregar o Dataset de Tweets em PIG</h1>\n<p>O processo é semelhante ao feito no Dataset da tabela Users.</p>\n</div>"}]}},{"title":"PIG: carregando dataset de tweets","text":"%pig\n\nTweets = LOAD '/data/tweets.csv' using PigStorage(',') as (\n      id: chararray, \n      text: chararray, \n      created_at: chararray, \n      in_reply_to_status_id_str: chararray, \n      in_reply_to_user_id_str: chararray, \n      in_reply_to_screen_name: chararray, \n      user_id: chararray, \n      place_id: chararray, \n      quoted_status_id: chararray, \n      is_quote_status: boolean,\n      retweeted_status_id: chararray, \n      retweet_count: int,\n      favorite_count: int,\n      lang: chararray\n);","dateUpdated":"2017-12-12T17:55:15+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315932_-716560356","id":"20171130-200029_1716373258","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5473"},{"text":"%md\n# Como carregar um dataset da tabela Tweet e criar um DataFrame\n\nNo caso do Spark, existe uma semelhança na leitura dos dados com o PIG, uma vez que ambos terão que definir o nome e os tipos dos parâmetros. \n\n**1. Primeiro passo**: definir uma classe ( **Tweet**) cujos atributos determinam o nome e o tipo de todos os parâmetros.\n\n**2. Segundo passo**: definir uma função ( **mapper**) que transforme uma linha de texto do dataset em um objeto da classe definida. Utilizamos funções auxiliares para conversão das strings de valores do tipo inteiro ( **convertToInt**) e booleano ( **convertToBool**), as quais estão presentes no carregamento anterior da classe USers, então elas são usadas, mas não precisam ser reescritas aqui. \n\n**3. Terceiro Passo**: realizar a leitura das linhas de texto do arquivo do dataset, mapeando cada linha para a função definida (mapper), resultando em um Array de **Tweet**.\n\n**4. Quarto Passo**: criar o DataFrame a partir do RDD existente e em seguida, imprimir esse schema.\n","user":"anonymous","dateUpdated":"2017-12-13T01:31:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513127674052_-2133392682","id":"20171213-011434_1345947300","dateCreated":"2017-12-13T01:14:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8355","dateFinished":"2017-12-13T01:31:28+0000","dateStarted":"2017-12-13T01:31:28+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Como carregar um dataset da tabela Tweet e criar um DataFrame</h1>\n<p>No caso do Spark, existe uma semelhança na leitura dos dados com o PIG, uma vez que ambos terão que definir o nome e os tipos dos parâmetros. </p>\n<p><strong>1. Primeiro passo</strong>: definir uma classe ( <strong>Tweet</strong>) cujos atributos determinam o nome e o tipo de todos os parâmetros.</p>\n<p><strong>2. Segundo passo</strong>: definir uma função ( <strong>mapper</strong>) que transforme uma linha de texto do dataset em um objeto da classe definida. Utilizamos funções auxiliares para conversão das strings de valores do tipo inteiro ( <strong>convertToInt</strong>) e booleano ( <strong>convertToBool</strong>), as quais estão presentes no carregamento anterior da classe USers, então elas são usadas, mas não precisam ser reescritas aqui. </p>\n<p><strong>3. Terceiro Passo</strong>: realizar a leitura das linhas de texto do arquivo do dataset, mapeando cada linha para a função definida (mapper), resultando em um Array de <strong>Tweet</strong>.</p>\n<p><strong>4. Quarto Passo</strong>: criar o DataFrame a partir do RDD existente e em seguida, imprimir esse schema.</p>\n</div>"}]}},{"title":"SPARK: carregando Dataset de Tweets e criando DataFrame","text":"%spark \n\nfinal case class Tweet(\n      id: String, \n      text: String, \n      created_at: String, \n      in_reply_to_status_id_str: String, \n      in_reply_to_user_id_str: String, \n      in_reply_to_screen_name: String, \n      user_id: String, \n      place_id: String, \n      quoted_status_id: String, \n      is_quote_status: Option[Boolean],\n      retweeted_status_id: String, \n      retweet_count: Option[Int],\n      favorite_count: Option[Int],\n      lang: String\n)\n\ndef mapper(line: String) : Tweet = {\n    val fields = line.split(\",\")\n    Tweet(\n        fields(0),\n        fields(1),\n        fields(2),\n        fields(3),\n        fields(4),\n        fields(5),\n        fields(6),\n        fields(7),\n        fields(8),\n        convertToBool(fields(9)),\n        fields(10),\n        convertToInt(fields(11)),\n        convertToInt(fields(12)), \n        fields(13)\n    )\n}\n\nval tweets = sc.textFile(\"/data/tweets.csv\").map(mapper)\n\nval tweetsDF = tweets.toDF\n\ntweetsDF.registerTempTable(\"tweets\")\ntweetsDF.printSchema\n","dateUpdated":"2017-12-13T01:25:47+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315932_-716560356","id":"20171205-162202_1944693946","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5474"},{"text":"%md\n\n# Questões abordadas:\n\nEssas questões foram elaboradas para utilizar os datasets de Usuários e Tweets e serão respondidas através de consultas feitas pelas ferramentas: PIG LATIN, SQL e SPARK SQL.\n\n**1. Quantos tweets de abuso online as mulheres recebem por hora?**\n**2. Quem são os usuários que enviam tweets abusivos?**\n**3. Qual é o volume de tweets abusivos por agressor/infrator?**\n\n","user":"anonymous","dateUpdated":"2017-12-13T00:37:26+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Questões abordadas:</h1>\n<p>Essas questões foram elaboradas para utilizar os datasets de Usuários e Tweets e serão respondidas através de consultas feitas pelas ferramentas: PIG LATIN, SQL e SPARK SQL.</p>\n<p><strong>1. Quantos tweets de abuso online as mulheres recebem por hora?</strong><br/><strong>2. Quem são os usuários que enviam tweets abusivos?</strong><br/><strong>3. Qual é o volume de tweets abusivos por agressor/infrator?</strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315932_-716560356","id":"20171130-204736_1575874948","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-13T00:37:26+0000","dateFinished":"2017-12-13T00:37:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5475"},{"text":"%md\n# Respondendo a Questão 1: Quantos tweets de abuso online as mulheres recebem por hora?\n\n\n","user":"anonymous","dateUpdated":"2017-12-13T00:46:31+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Respondendo a Questão 1: Quantos tweets de abuso online as mulheres recebem por hora?</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1513125766581_-390759813","id":"20171213-004246_56436717","dateCreated":"2017-12-13T00:42:46+0000","dateStarted":"2017-12-13T00:46:31+0000","dateFinished":"2017-12-13T00:46:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5476"},{"title":"[PIG LATIN] 1. Quantos tweets de abuso online as mulheres recebem por hora?","text":"%pig.query\n\nHour = FOREACH Tweets GENERATE REGEX_EXTRACT(created_at,'(\\\\S{3}) (\\\\S{3}) (\\\\S{2}) (\\\\S{2}):(\\\\S{2}):(\\\\S{2}) (\\\\S{5})',4) as hour, '1' as qty;\nGrouped = GROUP Hour BY hour;\nFOREACH Grouped GENERATE group as hour, COUNT(Hour) as qty;\n\n","dateUpdated":"2017-12-13T00:46:24+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"hour","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"qty","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315932_-716560356","id":"20171205-022733_1798589238","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5477"},{"title":"[SQL] 1. Quantos tweets de abuso online as mulheres recebem por hora?","text":"%sql\n\nSELECT hour, count(qty) as qty\n  FROM (SELECT REGEXP_EXTRACT(created_at,'(\\\\S{3}) (\\\\S{3}) (\\\\S{2}) (\\\\S{2}):(\\\\S{2}):(\\\\S{2}) (\\\\S{5})',4) AS hour, 1 AS qty\n        FROM tweets)\n GROUP BY hour\n \n","dateUpdated":"2017-12-13T00:39:16+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"hour","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"qty","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315932_-716560356","id":"20171208-001658_843731661","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5478"},{"title":"[SPARK SQL] 1. Quantos tweets de abuso online as mulheres recebem por hora?","text":"%spark\n\ntweetsDF.withColumn(\"created_at\", regexp_extract('created_at, \"(\\\\S{3}) (\\\\S{3}) (\\\\S{2}) (\\\\S{2}):(\\\\S{2}):(\\\\S{2}) (\\\\S{5})\", 4))\n        .select(\"created_at\",\"id\")\n        .groupBy(\"created_at\")\n        .count()\n        .show;\n","dateUpdated":"2017-12-13T00:39:27+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"hour","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"cnt","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315933_-716945105","id":"20171205-164854_1683117559","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5479"},{"text":"%md\n# Respondendo a Questão 2: Quem são os usuários que enviam tweets abusivos? \n","user":"anonymous","dateUpdated":"2017-12-13T00:44:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Respondendo a Questão 2: Quem são os usuários que enviam tweets abusivos?</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1513125769916_1280974158","id":"20171213-004249_1223582185","dateCreated":"2017-12-13T00:42:49+0000","dateStarted":"2017-12-13T00:44:58+0000","dateFinished":"2017-12-13T00:44:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5480"},{"title":"PIG LATIN: 2. Quem são os usuários que enviam tweets abusivos? ","text":"%pig.query\n\nUserIds = FOREACH Tweets GENERATE user_id;\nResult = JOIN Users BY id, UserIds BY user_id;\nResult = FOREACH Result GENERATE id, name, screen_name;\nResult = DISTINCT Result;\nORDER Result BY id;\n","dateUpdated":"2017-12-13T00:44:53+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"Users::id","index":0,"aggr":"sum"}],"groups":[],"values":[]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315933_-716945105","id":"20171205-023324_516204895","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5481"},{"title":"[SQL] 2. Quem são os usuários que enviam tweets abusivos?","text":"%sql\n\nSELECT DISTINCT user_id, name, screen_name\n  FROM Tweets t\n  JOIN Users u\n    ON t.user_id = u.id\n ORDER BY user_id\n","dateUpdated":"2017-12-13T00:39:54+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"Users::id","index":0,"aggr":"sum"}],"groups":[],"values":[]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315933_-716945105","id":"20171208-011428_747517533","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5482"},{"title":"[SPARK SQL] 2. Quem são os usuários que enviam tweets abusivos?","text":"%spark\n\ntweetsDF.join(usersDF, tweetsDF(\"user_id\")===usersDF(\"id\"))\n        .select(\"user_id\", \"name\", \"screen_name\")\n        .orderBy(asc(\"user_id\"))\n        .distinct\n        .show\n","dateUpdated":"2017-12-13T00:40:02+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315933_-716945105","id":"20171205-163055_644328757","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5483"},{"text":"%md\n# Respondendo a Questão 3: Qual é o volume de tweets abusivos por agressor/infrator?\n","user":"anonymous","dateUpdated":"2017-12-13T00:45:06+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Respondendo a Questão 3: Qual é o volume de tweets abusivos por agressor/infrator?</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1513125635644_371611648","id":"20171213-004035_1860394526","dateCreated":"2017-12-13T00:40:35+0000","dateStarted":"2017-12-13T00:45:06+0000","dateFinished":"2017-12-13T00:45:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5484"},{"title":"[PIG LATIN] 3. Qual é o volume de tweets abusivos por agressor/infrator?","text":"%pig.query\n\nUserInfo = FOREACH Users GENERATE id, screen_name; \nUniqUsers = DISTINCT UserInfo;\nUserIds = FOREACH Tweets GENERATE user_id;\nJoined = JOIN UniqUsers BY id, UserIds BY user_id;\nGrouped = GROUP Joined By screen_name;\nResult = FOREACH Grouped GENERATE group as screen_name, COUNT(Joined) as qty;\nResultOrdered = ORDER Result BY qty DESC;\n\nLIMIT ResultOrdered 10;\n","dateUpdated":"2017-12-13T00:42:02+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"screen_name","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"qty","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1513101315933_-716945105","id":"20171205-023326_1600397485","dateCreated":"2017-12-12T17:55:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5485"},{"title":"[SQL] 3. Qual é o volume de tweets abusivos por agressor/infrator?","text":"%sql \n\nSELECT screen_name, count(user_id) as qty\n  FROM (SELECT DISTINCT id, screen_name\n          FROM Users) u\n  JOIN Tweets t\n    ON u.id = t.user_id\n GROUP BY screen_name\n ORDER BY qty DESC\n LIMIT 10\n","user":"anonymous","dateUpdated":"2017-12-13T00:31:15+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"screen_name","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"qty","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Table or view not found: Users; line 3 pos 15\nset zeppelin.spark.sql.stacktrace = true to see full stacktrace"}]},"apps":[],"jobName":"paragraph_1513101315934_-715790858","id":"20171208-014010_873451638","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T18:00:08+0000","dateFinished":"2017-12-12T18:01:48+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5486"},{"title":"[SPARK SQL] 3.  Qual é o volume de tweets abusivos por agressor/infrator?","text":"%spark\n\nusersDF.select(\"id\", \"screen_name\")\n       .distinct\n       .join(tweetsDF, usersDF(\"id\")===tweetsDF(\"user_id\"))\n       .groupBy(\"screen_name\")\n       .count\n       .orderBy(desc(\"count\"))\n       .show\n","user":"anonymous","dateUpdated":"2017-12-13T00:31:13+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"screen_name","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"qty","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:26: error: not found: value usersDF\n       usersDF.select(\"id\", \"screen_name\")\n       ^\n<console>:28: error: not found: value tweetsDF\n              .join(tweetsDF, usersDF(\"id\")===tweetsDF(\"user_id\"))\n                    ^\n<console>:28: error: not found: value usersDF\n              .join(tweetsDF, usersDF(\"id\")===tweetsDF(\"user_id\"))\n                              ^\n<console>:28: error: not found: value tweetsDF\n              .join(tweetsDF, usersDF(\"id\")===tweetsDF(\"user_id\"))\n                                              ^\n"}]},"apps":[],"jobName":"paragraph_1513101315934_-715790858","id":"20171208-014709_832146852","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T18:00:13+0000","dateFinished":"2017-12-12T18:01:48+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5487"},{"text":"%md\n# Respondendo a questão 4: Quais as expressões de raiva mais comuns online?\n\nEssa questão 4 não foi respondida,em SQL e SPARK apenas em PIG LATIN que já tinha sido feito anteriormente.\n","user":"anonymous","dateUpdated":"2017-12-13T00:45:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Respondendo a questão 4: Quais as expressões de raiva mais comuns online?</h1>\n<p>Essa questão 4 não foi respondida,em SQL e SPARK apenas em PIG LATIN que já tinha sido feito anteriormente.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1513101315934_-715790858","id":"20171205-024952_1573796455","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-13T00:45:54+0000","dateFinished":"2017-12-13T00:45:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5488"},{"title":"[PIG]Questão 4. Quais as expressões de raiva mais comuns online?","text":"%pig\n\nREGISTER /data/tutorial.jar\nLowered = FOREACH Tweets GENERATE id, org.apache.pig.tutorial.ToLower(text) as tweet;\nNgram = FOREACH Lowered GENERATE id, flatten(org.apache.pig.tutorial.NGramGenerator(tweet)) as ngram;\nNgram = FILTER Ngram BY SIZE(ngram) > 6;\nNgram = DISTINCT Ngram;\nGrouped = GROUP Ngram BY (ngram);\nFrequency = FOREACH Grouped GENERATE group, COUNT(Ngram) as count;\nMostUsed = FILTER Frequency BY count > 20;\nResult = ORDER MostUsed BY count DESC;\n\nDUMP Result;","user":"anonymous","dateUpdated":"2017-12-13T00:28:09+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"pig","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/pig","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[]},"apps":[],"jobName":"paragraph_1513101315934_-715790858","id":"20171205-023327_1035076126","dateCreated":"2017-12-12T17:55:15+0000","dateStarted":"2017-12-12T17:59:52+0000","dateFinished":"2017-12-12T17:59:56+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:5489"}],"name":"PIG vs SPARK 2","id":"2D2EY11MD","angularObjects":{"2D4233C1B:shared_process":[],"2CZN8EC3Z:shared_process":[],"2D43P1MDS:shared_process":[],"2D2QHZXB2:shared_process":[],"2D1YFE9X6:shared_process":[],"2D1FN6FXP:shared_process":[],"2D29Q8H9A:shared_process":[],"2CZGN3PCU:shared_process":[],"2D2CYD8NK:shared_process":[],"2D2KT543G:shared_process":[],"2D2GF26ZZ:shared_process":[],"2D26TV7GV:shared_process":[],"2CZNZMFQW:shared_process":[],"2CZFUHAJ5:shared_process":[],"2D39TAZ8T:shared_process":[],"2D3BF96DW:shared_process":[],"2D3FNVCF1:shared_process":[],"2D41ANCVE:shared_process":[],"2CZF37DAE:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}